{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc1f643-5de2-4443-844e-1947871f134d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "os.environ['http_proxy'] = \"http://proxy-ws.cbank.kz:8080\"\n",
    "os.environ['https_proxy'] = \"http://proxy-ws.cbank.kz:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "198b7468-828b-486b-973b-6c4ac773f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('{} device is available'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f58438-3338-4120-bb2c-d4ba336c2a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-27 05:19:53--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
      "Resolving proxy-ws.cbank.kz (proxy-ws.cbank.kz)... 10.1.246.2\n",
      "Connecting to proxy-ws.cbank.kz (proxy-ws.cbank.kz)|10.1.246.2|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 262521 (256K) [text/plain]\n",
      "Saving to: ‘onegin.txt.2’\n",
      "\n",
      "onegin.txt.2        100%[===================>] 256.37K   827KB/s    in 0.3s    \n",
      "\n",
      "2024-11-27 05:19:53 (827 KB/s) - ‘onegin.txt.2’ saved [262521/262521]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16eb8fc9-6e82-4eaa-ac36-1fb9ed206873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni\\n\\n«мой дядя самых честных правил,\\nкогда не в шутку занемог,\\nон уважать себя заставил\\nи лучше выдум'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f8694-1f3e-47ab-ae76-e08ecd631e65",
   "metadata": {},
   "source": [
    "### Создадим буквенно-символьные токены и дадим им индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af9a657-971e-43ed-89ac-9b002a87e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(text.lower())) + ['<sos>']\n",
    "\n",
    "token_to_index = { x : index for index, x in enumerate(tokens) }\n",
    "index_to_token = { index : x for index, x in enumerate(tokens) }\n",
    "\n",
    "assert len(tokens) == 84, \"Check the tokenization process\"\n",
    "assert len(tokens) == len(token_to_index)\n",
    "\n",
    "text_encoded = [token_to_index[token] for token in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7913d91b-6226-4159-a4f1-ab534dcd0c7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 26, 0, 0, 43, 57, 59, 54, 1, 49]\n"
     ]
    }
   ],
   "source": [
    "print(text_encoded[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c25dca-726c-401a-a738-cd92dd7dfc19",
   "metadata": {},
   "source": [
    "#### Рандомные чанки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf1f82f-babf-41ba-8354-945630ffa5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "seq_length = 100\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_index['<sos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18b15aa5-0881-4966-9636-05cdaff5bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
    "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63a17b-d8d6-4c84-a2b1-a99fad97bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = next(generate_chunk())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "424d6eca-88dc-4e72-a538-b07cf86bb00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 101)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e08921b4-30e7-42cb-973b-ccba60566a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 53, 58, ..., 66,  7,  0],\n",
       "       [83, 47,  1, ...,  5,  1, 49],\n",
       "       [83, 45, 47, ..., 61, 59, 49],\n",
       "       ...,\n",
       "       [83, 61,  1, ..., 47, 56, 45],\n",
       "       [83, 49, 53, ..., 58, 59, 69],\n",
       "       [83, 45,  6, ..., 45, 56,  1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d252874b-7972-4040-afd1-3b84e47b47f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[83, 53, 58,  ..., 66,  7,  0],\n",
       "        [83, 47,  1,  ...,  5,  1, 49],\n",
       "        [83, 45, 47,  ..., 61, 59, 49],\n",
       "        ...,\n",
       "        [83, 61,  1,  ..., 47, 56, 45],\n",
       "        [83, 49, 53,  ..., 58, 59, 69],\n",
       "        [83, 45,  6,  ..., 45, 56,  1]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.LongTensor(chunk)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "202a2960-dc9f-4b47-bd4f-df8beccac6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.nn.Embedding(seq_length + 1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0a8ddb2-3e0c-46b8-b384-7db546d75c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_input = (1, input_size)\n",
    "# W_input_hidden = (input_size, hidden_size)\n",
    "\n",
    "# current_state = x_input * W_input_hidden = (1, hidden_size)\n",
    "\n",
    "# last_state = (1, hidden_size)\n",
    "# W_hidden_hidden = (hidden_size, hidden_size)\n",
    "\n",
    "# from_last_state = last_state * W_hidden_hidden\n",
    "# from_last_state = (1, hidden_size)\n",
    "\n",
    "# go_to_next_state = current_state + from_last_state\n",
    "\n",
    "# h_init = (1, hidden_size) from normal(0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea399265-b12e-46a2-9de6-e7c26fe886cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNcell(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embed = torch.nn.Embedding(input_size, 112)\n",
    "        self.W = torch.nn.Linear(hidden_size + input_size, hidden_size)\n",
    "        # self.W_classify = torch.nn.Linear(hidden_size, num_tokens)\n",
    "        \n",
    "    def forward(self, prev_hidden, input_X):\n",
    "        # input_X = (batch_size, input_size)\n",
    "        print(\"prev_hidden: \", prev_hidden.shape)\n",
    "        print(\"input_X: \", input_X.shape)\n",
    "\n",
    "        embedding = embed(input_X)\n",
    "\n",
    "        print(\"embedding size: \", embedding.shape)\n",
    "                \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f1e4eac-0341-412a-bf03-53f74ba5aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9ca077c1-0b54-46a4-a012-29dab2ada950",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = RNNcell(seq_length + 1, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d336fc4b-202a-4eac-b6d8-a1d4049f6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = torch.zeros(1, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94e0b318-722b-44f4-a010-4a2b117ab743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_hidden:  torch.Size([1, 50])\n",
      "input_X:  torch.Size([101])\n",
      "embedding size:  torch.Size([101, 256])\n"
     ]
    }
   ],
   "source": [
    "res = rnn_cell.forward(init_state, batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01679e40-f021-4f5d-89a0-f8526bdd2eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58193ef4-fe97-4a31-afd0-977021007368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 53, 58, ..., 66,  7,  0],\n",
       "       [83, 47,  1, ...,  5,  1, 49],\n",
       "       [83, 45, 47, ..., 61, 59, 49],\n",
       "       ...,\n",
       "       [83, 61,  1, ..., 47, 56, 45],\n",
       "       [83, 49, 53, ..., 58, 59, 69],\n",
       "       [83, 45,  6, ..., 45, 56,  1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f7961-c7fa-459b-9090-336209e66d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = (batch_size, input_size)\n",
    "# Embedding_size = (input_size, embed_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
